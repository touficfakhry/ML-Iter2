{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "dataset_dir = \"../StanfordCarDataset\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing/Resizing the images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_image(image):\n",
    "  image_array = np.array(image)\n",
    "  normalized_array = image_array / 255.0\n",
    "  return Image.fromarray((normalized_array * 255).astype(np.uint8))\n",
    "\n",
    "def denoise_image(image):\n",
    "  # Apply median filtering (adjust kernel size as needed)\n",
    "  image = cv2.medianBlur(image, ksize=5)\n",
    "\n",
    "  # Normalize the image\n",
    "  return normalize_image(image)\n",
    "\n",
    "def preprocess_image(image):\n",
    "  return normalize_image(image)\n",
    "  # no need for denoising now\n",
    "  # denoise_image(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing images by resizing and normalizing them.\n",
    "\n",
    "Saving the new images in new train and test directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_folder = f\"{dataset_dir}/cars_train/cars_train\"\n",
    "train_output_folder = f\"{dataset_dir}/resized_dataset_train\"\n",
    "\n",
    "test_dataset_folder = f\"{dataset_dir}/cars_test/cars_test\"\n",
    "test_output_folder = f\"{dataset_dir}/resized_dataset_test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_images(dataset_folder, output_folder, target_size, force_update=False):\n",
    "    if os.path.isdir(output_folder) and len(os.listdir(output_folder)) != 0 and not force_update:\n",
    "        return\n",
    "    # Loop through all images in the dataset folder\n",
    "    for filename in os.listdir(dataset_folder):\n",
    "        # Skiping non-image files in case any\n",
    "        if not filename.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "            continue\n",
    "\n",
    "        image_path = os.path.join(dataset_folder, filename)\n",
    "        image = Image.open(image_path)\n",
    "\n",
    "        resized_image = image.resize(target_size, Image.LANCZOS)\n",
    "\n",
    "        if image.mode != 'RGB':\n",
    "            resized_image = resized_image.convert('RGB')\n",
    "            \n",
    "        resized_image = preprocess_image(resized_image)\n",
    "\n",
    "        # Saving the resized image\n",
    "        output_path = os.path.join(output_folder, filename)\n",
    "        resized_image.save(output_path)\n",
    "\n",
    "os.makedirs(train_output_folder, exist_ok=True)\n",
    "os.makedirs(test_output_folder, exist_ok=True)\n",
    "\n",
    "resize_images(train_dataset_folder, train_output_folder, target_size=(224, 224))\n",
    "resize_images(test_dataset_folder, test_output_folder, target_size=(224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_image_features_extraction_model():\n",
    "    base_model = VGG16(weights='imagenet', include_top=True)\n",
    "    # Retrieve the last dense layer name\n",
    "    last_dense_layer_name = base_model.layers[-2].name\n",
    "    # return Model(inputs=base_model.input, outputs=base_model.get_layer('block5_pool').output)\n",
    "    # Create a new model for feature extraction from the last dense layer\n",
    "    return Model(inputs=base_model.input, outputs=base_model.get_layer(last_dense_layer_name).output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_image_features_as_list(feature_extractor, dir_path, max_iterations=-1):\n",
    "    #train_output_folder\n",
    "    features_list = []\n",
    "    count = 0\n",
    "    for filename in os.listdir(dir_path):\n",
    "        if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
    "            # Load and preprocess the image\n",
    "            img_path = os.path.join(dir_path, filename)\n",
    "            img = Image.open(img_path)\n",
    "            img_array = np.array(img)\n",
    "            # add batch dimensions\n",
    "            img_array = np.expand_dims(img_array, axis=0)\n",
    "            img_array = img_array / 255.0\n",
    "\n",
    "            # Extract features from the image\n",
    "            features = feature_extractor.predict(img_array)\n",
    "\n",
    "            # Append the features to the list\n",
    "            features_list.append(features)\n",
    "\n",
    "            count += 1\n",
    "            if max_iterations > 0 and count >= max_iterations:\n",
    "                break\n",
    "\n",
    "    return features_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\toufic.f\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2440, in predict_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\toufic.f\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2425, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\toufic.f\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2413, in run_step  **\n        outputs = model.predict_step(data)\n    File \"c:\\Users\\toufic.f\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2381, in predict_step\n        return self(x, training=False)\n    File \"c:\\Users\\toufic.f\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\toufic.f\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"model_7\" is incompatible with the layer: expected shape=(None, 224, 224, 3), found shape=(None, 400, 600, 3)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m feature_extractor \u001b[38;5;241m=\u001b[39m build_image_features_extraction_model()\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Iterate over the images in the directory\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m features_list \u001b[38;5;241m=\u001b[39m \u001b[43mextract_image_features_as_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature_extractor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_output_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iterations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# features_array = np.vstack(features_list)\u001b[39;00m\n\u001b[0;32m      7\u001b[0m features_list_flattened \u001b[38;5;241m=\u001b[39m [features\u001b[38;5;241m.\u001b[39mreshape(features\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m features \u001b[38;5;129;01min\u001b[39;00m features_list]\n",
      "Cell \u001b[1;32mIn[17], line 16\u001b[0m, in \u001b[0;36mextract_image_features_as_list\u001b[1;34m(feature_extractor, dir_path, max_iterations)\u001b[0m\n\u001b[0;32m     13\u001b[0m img_array \u001b[38;5;241m=\u001b[39m img_array \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255.0\u001b[39m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Extract features from the image\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[43mfeature_extractor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_array\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Append the features to the list\u001b[39;00m\n\u001b[0;32m     19\u001b[0m features_list\u001b[38;5;241m.\u001b[39mappend(features)\n",
      "File \u001b[1;32mc:\\Users\\toufic.f\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filegqhuo2x5.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\toufic.f\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2440, in predict_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\toufic.f\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2425, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\toufic.f\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2413, in run_step  **\n        outputs = model.predict_step(data)\n    File \"c:\\Users\\toufic.f\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2381, in predict_step\n        return self(x, training=False)\n    File \"c:\\Users\\toufic.f\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\toufic.f\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"model_7\" is incompatible with the layer: expected shape=(None, 224, 224, 3), found shape=(None, 400, 600, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "feature_extractor = build_image_features_extraction_model()\n",
    "\n",
    "# Iterate over the images in the directory\n",
    "features_list = extract_image_features_as_list(feature_extractor, train_output_folder, max_iterations=10)\n",
    "\n",
    "# features_array = np.vstack(features_list)\n",
    "features_list_flattened = [features.reshape(features.shape[0], -1) for features in features_list]\n",
    "\n",
    "# Convert the numpy array to a pandas DataFrame\n",
    "features_df = pd.DataFrame(np.concatenate(features_list_flattened, axis=0))\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "features_df.to_csv('extracted_features.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
