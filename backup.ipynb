{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over the train_generator and attempt to load each image\n",
    "for i, batch in enumerate(train_generator):\n",
    "    # Get the images from the batch\n",
    "    images = batch[0]\n",
    "    \n",
    "    # Attempt to load each image\n",
    "    for j, img_array in enumerate(images):\n",
    "        try:\n",
    "            # Convert the image array to a PIL image\n",
    "            img = Image.fromarray(np.uint8(img_array*255))  # Assuming images are normalized\n",
    "            \n",
    "            # Check if the image can be loaded\n",
    "            img.load()\n",
    "        except Exception as e:\n",
    "            # Print the error message along with the filename or index of the problematic image\n",
    "            print(f\"Error loading image at index {i*train_generator.batch_size + j}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_folder = f\"{dataset_dir}/resized_dataset_train\"\n",
    "test_dataset_folder = f\"{dataset_dir}/resized_dataset_test\"\n",
    "train_datagen = ImageDataGenerator(\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    rotation_range=20,\n",
    "    preprocessing_function=preprocess_image\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_image\n",
    ")\n",
    "\n",
    "\n",
    "train_image_files = [os.path.join(train_dataset_folder, f) for f in os.listdir(train_dataset_folder) if f.endswith(('jpg', 'jpeg', 'png'))]\n",
    "test_image_files = [os.path.join(test_dataset_folder, f) for f in os.listdir(test_dataset_folder) if f.endswith(('jpg', 'jpeg', 'png'))]\n",
    "\n",
    "# Create training and validation image generators\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=pd.DataFrame({'filename': train_image_files}),\n",
    "    x_col='filename',\n",
    "    class_mode=None,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "validation_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe=pd.DataFrame({'filename': test_image_files}),\n",
    "    x_col='filename',\n",
    "    class_mode=None,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the CNN\n",
    "model = Sequential()\n",
    "\n",
    "# Convolutional layer 1\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(224, 224, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Convolutional layer 2\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Convolutional layer 3\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flattening\n",
    "model.add(Flatten())\n",
    "\n",
    "# Fully connected layers\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))  # Output layer\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define early stopping to prevent overfitting\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=10,  # Adjust epochs based on training time and validation performance\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=len(validation_generator),\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "loss, accuracy = model.evaluate(test_set)\n",
    "print(f\"Test loss: {loss}, Test accuracy: {accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
